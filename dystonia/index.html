<!-- 
    References:
    https://github.com/tensorflow/tfjs-models/tree/master/pose-detection
    https://github.com/tensorflow/tfjs-models/tree/master/pose-detection/src/movenet
    https://storage.googleapis.com/tfjs-models/demos/pose-detection/index.html?model=movenet
    https://github.dev/tensorflow/tfjs-models/blob/master/pose-detection/demos/live_video/src/index.js
    https://github.com/PAIR-code/scatter-gl
 -->
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>XDP: Neck Distortion Test</title>

    <!-- Require the peer dependencies of pose-detection. -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter" crossorigin="anonymous"></script>

    <!-- You must explicitly require a TF.js backend if you're not using the TF.js union bundle. -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl" crossorigin="anonymous"></script>
    <!-- Alternatively you can use the WASM backend: <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm/dist/tf-backend-wasm.js"></script> -->

    <!-- Scatter GL -->
    <!-- Load three.js -->
    <script src="https://cdn.jsdelivr.net/npm/three@0.106.2/build/three.min.js"></script>
    <!-- Load scatter-gl.js -->
    <script src="https://cdn.jsdelivr.net/npm/scatter-gl@0.0.1/lib/scatter-gl.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection" crossorigin="anonymous"></script>

    <script src="./params.js"></script>
    <script src="./util.js"></script>
    <script src="./camera.js"></script>
    <style>
        body {
            margin: 0;
        }

        #canvas-wrapper,
        #scatter-gl-container {
            position: relative;
        }
    </style>
</head>

<body>
    <div id="main">
        <div class="container">
            <div class="canvas-wrapper">
                <canvas id="output"></canvas>
                <video id="video" playsinline style="
              -webkit-transform: scaleX(-1);
              transform: scaleX(-1);
              visibility: hidden;
              width: auto;
              height: auto;
              ">
                </video>
            </div>
            <div id="scatter-gl-container"></div>
        </div>
        <script>
            let detector
            let camera, stats;
            let startInferenceTime, numInferences = 0;
            let inferenceTimeSum = 0, lastPanelUpdate = 0;
            let rafId;

            async function renderResult() {
                if (camera.video.readyState < 2) {
                    await new Promise((resolve) => {
                        camera.video.onloadeddata = () => {
                            resolve(video);
                        };
                    });
                }

                let poses = null;

                // Detector can be null if initialization failed (for example when loading
                // from a URL that does not exist).
                if (detector != null) {
                    // FPS only counts the time it takes to finish estimatePoses.
                    // beginEstimatePosesStats();

                    // Detectors can throw errors, for example when using custom URLs that
                    // contain a model that doesn't provide the expected output.
                    try {
                        poses = await detector.estimatePoses(
                            camera.video,
                            { maxPoses: 1, flipHorizontal: false });
                    } catch (error) {
                        detector.dispose();
                        detector = null;
                        alert(error);
                    }

                    // endEstimatePosesStats();
                }

                camera.drawCtx();

                // The null check makes sure the UI is not in the middle of changing to a
                // different model. If during model change, the result is from an old model,
                // which shouldn't be rendered.
                if (poses && poses.length > 0) {
                    camera.drawResults(poses);
                }
            }

            async function renderPrediction() {
                // await checkGuiUpdate();

                // if (!STATE.isModelChanged) {
                await renderResult();
                // }

                rafId = requestAnimationFrame(renderPrediction);
            };

            async function app() {
                // Gui content will change depending on which model is in the query string.


                camera = await Camera.setupCamera(STATE.camera);

                // await setBackendAndEnvFlags(STATE.flags, STATE.backend);

                detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet)

                renderPrediction();
            };

            app();
        </script>
</body>

</html>