<!--
    References:
    https://blog.tensorflow.org/2021/11/3D-handpose.html
    https://github.com/tensorflow/tfjs-models/tree/master/hand-pose-detection/demos#upload-a-video-demo
    https://google.github.io/mediapipe/solutions/hands#palm-detection-model
-->
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>XDP: Finger Tapping Test</title>


    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3/camera_utils.js"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4/hands.js" crossorigin="anonymous"></script>
</head>

<body>
    <div id="alert"></div>
    <!-- Uncomment to use upload based prediction -->
    <!-- <input type="file" id="videofile" name="video" accept="video/*">
    <button type="button" id="submit">Run</button> -->

    <button id="startTestBtn">Start Test</button>
    <button id="stopTestBtn">End Test</button>
    <div class="container" id="canvas-wrapper">
        <div id="videoMsgBox"></div>
        <canvas id="output" style="width: 640px; height: 310px"></canvas>
        <video id="video">
            <source id="currentVID" src="" type="video/mp4">
        </video>
    </div>
    <div id="score"></div>

    <script type="module">
        let initReadyStatus = false;
        const alertStatusBox = document.getElementById('alert');
        const video = document.getElementById('video');
        const videoMsgBox = document.getElementById('videoMsgBox');
        const result = document.getElementById('score');
        const canvasElement = document.getElementById('output');
        const canvasCtx = canvasElement.getContext('2d');
        const startTestBtn = document.getElementById('startTestBtn');
        const stopTestBtn = document.getElementById('stopTestBtn');
        let detector, camera, rafId, hands;

        class FingerTappingMetric {
            constructor() {
                this.tapThreshold = 0.1
                this.count = 0 // number of times thumb and index finger met
                this.isBeingTapped = false; // are the fingers currently being tapped
                this.prevTapState = false;
                this.avgTapDuration = 0;
                this.tapFreq = 0
                this.testInProgress = false;
                this.tapTs = []
                this.lastTapTs = -1;
                this.testStartTs = -1;
                this.totalTestDuration = 0
            }

            startTest() {
                this.testInProgress = true
                this.testStartTs = new Date().getTime()
            }

            stopTest() {
                this.testInProgress = false
                this.totalTestDuration += new Date().getTime() - this.testStartTs
                this.computeLapMetrics();
            }

            computeLapMetrics() {
                this.tapFreq = this.totalTestDuration / this.count;
            }

            compute(handLandmarks) {
                if (!this.testInProgress) {
                    return;
                }

                const results = {}
                let p1, p2
                results["thumb"] = p1 = [handLandmarks[4]['x'], handLandmarks[4]['y']]
                results["index"] = p2 = [handLandmarks[8]['x'], handLandmarks[8]['y']]
                results["distance"] = Math.sqrt(Math.pow(p2[0] - p1[0], 2) + Math.pow(p2[1] - p1[1], 2))
                this.prevTapState = this.isBeingTapped;
                this.isBeingTapped = results['distance'] < this.tapThreshold
                if (!this.prevTapState && this.isBeingTapped) {
                    this.count++;
                    const currTapTs = new Date().getTime();
                    this.tapTs.push(currTapTs)
                    if (this.lastTapTs > 0) {
                        // first tap as warm up for some metrics
                        const tapCountWithoutWarmup = this.count - 1;
                        const tapDuration = currTapTs - this.lastTapTs
                        this.avgTapDuration = (this.avgTapDuration * (tapCountWithoutWarmup - 1) + tapDuration) / tapCountWithoutWarmup
                    }
                    this.lastTapTs = currTapTs
                }
            }
        }

        const ftm = new FingerTappingMetric()

        function onResults(results) {
            videoMsgBox.innerHTML = ""
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);
            if (results.multiHandLandmarks) {
                for (const landmarks of results.multiHandLandmarks) {
                    drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, { color: '#00FF00', lineWidth: 3 });
                    drawLandmarks(canvasCtx, landmarks, { color: '#FF0000', lineWidth: 1, radius: 3 });
                    computeAndShowMetric(landmarks)
                }
            }
            canvasCtx.restore();
        }

        function computeAndShowMetric(handLandmarks) {
            ftm.compute(handLandmarks)
            // result.innerHTML = `${ftm.prevTapState}, ${ftm.isBeingTapped}, ${ftm.count}, ${(ftm.avgTapDuration / 1000).toFixed(3)}s, ${(ftm.tapFreq / 1000).toFixed(3)}s`
            result.innerHTML = `
                <strong> Number of taps in this test:</strong> ${ftm.count} <br />
                <strong> Average tap duration:</strong> ${(ftm.avgTapDuration / 1000).toFixed(3)}s <br />
                <strong> Tap Frequency:</strong> ${(ftm.tapFreq / 1000).toFixed(3)}s <br />
            `
        }

        function initLiveFeed() {
            video.style.display = "none"; // hide the live video and only show the annotated video

            videoMsgBox.innerHTML = "Loading the test predictor model, please wait."

            const hands = new Hands({
                locateFile: (file) => {
                    return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
                }
            });
            hands.setOptions({
                maxNumHands: 2,
                modelComplexity: 1,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });
            hands.onResults(results => {
                // result.innerHTML = JSON.stringify(results.multiHandWorldLandmarks, null, 2)
                onResults(results)
            });

            const camera = new Camera(video, {
                onFrame: async () => {
                    await hands.send({ image: video });
                },
                width: 640,
                height: 310
            });
            camera.start();

            startTestBtn.onclick = () => {
                alertStatusBox.innerHTML = `Test in progress`
                ftm.startTest()
            }
            stopTestBtn.onclick = () => {
                alertStatusBox.innerHTML = ``
                ftm.stopTest()
            }

        }

        function extractTestLandmarks(multiHandWorldLandmarks) {
            const results = {}
            for (const handLandmark of multiHandWorldLandmarks) {
                results["thumb"] = [handLandmark[4]['x'], handLandmark[4]['y']]
                results["index"] = [handLandmark[8]['x'], handLandmark[8]['y']]
            }
            return results;
        }

        initLiveFeed();
    </script>
</body>

</html>